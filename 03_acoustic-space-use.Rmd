---
editor_options: 
  chunk_output_type: console
---

Install necessary libraries
```{r}
library(seewave)
library(warbleR)
library(tuneR)
library(stringi)
library(tidyverse)
library(ggplot2)
library(RColorBrewer)
library(foreach)
library(doParallel)

# Source any custom/other internal functions necessary for analysis
source("code/01_internal-functions.R")
```


Exploratory data analysis - Here I will try a few different functions from the seewave package in R to get a better sense of the distribution of frequencies over time
```{r}
# Read a sample .wav file
a <- tuneR::readWave("data\\20200307_083000.wav")

# Soundscape frequency spectrum of a time wave

# This function returns a kHz binned spectrum as described by Kasten et al. (2012) for the description of a soundscape.
# This function essentially creates a bar plot of frequencies in kHZ by amplitude values
s_spectr <- soundscapespec(a)
```

Acoustic Space Use (ASU)

We are interested in creating a three-dimensional matrix of acoustic activity (x=hour, y=acoustic frequencies, z=proportion of all recordings in each time/frequency bin)

Aide et al. 2017: We aggregated recordings at time scale of hour of day and used a frequency bin size of 86.13 Hz and an amplitude filtering threshold of 0.02. So if the sampling rate is 22000 Hz, that would mean - 22000/86.13 ~ 256 frequency bins to divide up the frequency space. In this paper, there would be 24hr*256 bins = 6144 time/frequency bins

Campos-Cerqueira et al. 2019: We aggregated recordings at the time scale of hour of day (24 h), used a frequency bin size of 172 Hz, and an amplitude filtering threshold of 0.003. So if the sampling rate is 22000 Hz, that would mean - 22000/172 ~ 128 frequency bins. This resulted in a three‐dimensional (x = hour, y = acoustic frequency, z = proportion of all recordings in each time/frequency bin with a frequency peak value > 0.003 amplitude) matrix of acoustic activity with a total of 3,072 time/frequency bins (24 h × 128 frequency bins).

Campos-Cerqueira and Aide 2017: To calculate the amplitude, we used the meanspec (f = 44,100, wl = 256, wn = “hanning”) and fpeaks (threshold = 0.1, freq = 172) function from the seewave package in R (Sueur et al., 2008a). The value of each peak was normalized using the maximum amplitude value within all recordings in the soundscape (i.e., site), and thus values ranged from 0 to 1. The number of frequency peaks was determined by counting the number of recordings with a peak within each of the 128 frequency bins that were equal or greater than the amplitude threshold. To control for the different number of recordings in each site and each time interval (i.e., hour), we divided the number of recordings with a peak in each time/frequency class by the total number of recordings collected during each hourly interval.

To calculate ASU: 

- A. Aggregate recordings for a multiple days across multiple sites (Keep only data that has been recorded continuously for a 24hr period)
```{r}
# List the path that contains all folders, which contain the audiomoth data
path <- "C:\\data\\"

# Listing the folders within which .WAV files are stored
folders <- dir(path, recursive=F,full.names=T)

# Let's first rename the files by name of each site (as prefix)
# Please note: The renaming needs to be done only a single time (else there will be errors)
for(i in 1:length(folders)){

setwd(folders[i])
  
# List the files within each folder and renaming the files with the prefix - SITE_ID
a <- list.files(paste0(path,basename(folders)[i],"\\"), full.names = T)
file.rename(from = a, to=paste0(basename(folders)[i],"_",basename(a)))
}


# Now get only those files for a full 24 hours across every unique site
files <- list()

for(i in 1:length(folders)){

a <- list.files(paste0(path,basename(folders)[i],"\\"), full.names = T)
site_date <- str_extract(basename(a),'\\w+_\\d+_')

# Choosing all 24 hours of data across every unique site (288 corresponds to 12 files every 1 hour)
  for(j in 1:length(unique(site_date))){
    dat <- a[str_detect(a,unique(site_date)[j])]
    if((length(dat)<288)==TRUE){
      next
    } else {
      files <- c(files, dat) 
    }
  }
}

files <- unlist(files)
```


- B. Aggregate recordings for any single day for every unique site and sort it in order (between 00:00:00 to 23:55:00 hrs) and then loop it across multiple days
```{r}
# Select all unique site combinations
site <- str_extract(basename(files),'^([[:alnum:]])+')
unique(site)

# Select all the site_date combinations for each unique site
site_date <- str_extract(basename(files),'\\w+_\\d+_')
unique(site_date)

# Create a sequence of numbers to combine files by 1 hour
hour_seq <- seq(from=0,to=288, by=12)

# To name files with a suffix for each hour
time_of_day <- c("00:00-01:00","01:00-02:00","02:00-03:00","03:00-04:00",
                 "04:00-05:00","05:00-06:00","06:00-07:00","07:00-08:00",
                 "08:00-09:00","09:00-10:00","10:00-11:00","11:00-12:00", 
                 "12:00-13:00","13:00-14:00","14:00-15:00","15:00-16:00",
                 "16:00-17:00","17:00-18:00","18:00-19:00","19:00-20:00",
                 "20:00-21:00","21:00-22:00","22:00-23:00","23:00-24:00")

# Loading parameters necessary for the Short-term fourier transform to be performed on
# hourly aggregates of data for each site_date combination
f <- 48000
wl <- 256 # Changing this to 256 to match Campos-Cerqueira et al. 2017 which results in 128 frequency bins
ovlp <- 0
wn <- "hanning"

# Store the 24 hour acoustic space use data in a list and name it by a unique site and date
site_date_asu <-  list()

# Setup parallel backend to use many processors
cores <- detectCores()
cl <- makeCluster(cores[1]-4) #not to overload your computer
doParallel::registerDoParallel(cl)

# Select only 24 hours of data (00:00:00 to 23:55:00) for every unique site
for (i in 1:length(unique(site))){
  
  # Extract the strings first by site 
  b <- files[str_detect(files,unique(site)[4])]
  
  # Extract the unique site_date string
  site_date <- unique(str_extract(basename(b),'\\w+_\\d+_'))
  
  # For each unique site_date combination for the given site
  for(j in 1:2){
    
    # Store the each hour of data as a list here
    hourlydata <- list()
    
    # Store the acoustic space use data in a data.frame for plotting
    space_use <- data.frame()

    dat <- b[stringr::str_detect(b,site_date[1])] # A unique 24 hours of recording/site
    
    for(k in 1:(length(hour_seq)-1)){
        d <- dat[hour_seq[k]:hour_seq[k+1]]
        tmp_list <- list()
      for(m in 1:length(d)){
        r <- tuneR::readWave(d[m])
        tmp_list<- c(tmp_list,r)
      }
      rm(r); gc()
      data_needed <- do.call(c,tmp_list)
      hourlydata <- c(hourlydata,data_needed)
      rm(data_needed, tmp_list); gc()
    }
    
    # Using the above hourlydata list created for a single site_date combination
    for(t in 1:length(hourlydata)){
        wave <- hourlydata[[t]]
        n <- length(wave)
        
        ## Short-term Fourier transform (using a seewave internal function)
        m <- sspectro(wave, f = f, wl = wl, ovlp = ovlp, wn = wn)

        # Frequency selection and frequency axis
        # Here, want only a sequence of numbers that correspond to the length of rows of the
        # short-time fourier transform and we divide it by 1000 to get values in kHz
        freq <- seq(0, (f/2) - (f/wl), length.out = nrow(m))/1000
        
        # Calculate acoustic space use per frequency bin 
        f.cont <- apply(m, MARGIN = 1, FUN = sum)
        f.cont <- f.cont/sum(f.cont)
        
        # Store the space use data in a dataframe for plotting later
        a <- data.frame(freq, f.cont,time_of_day=rep(time_of_day[t], each=length(f.cont)))
        space_use <- rbind(a, space_use)
        rm(m, wave); gc()
    }
    site_date_asu <- c(site_date_asu,list(space_use))
    names(site_date_asu)[j] <- site_date[j] 
    rm(hourlydata, space_use); gc()
}
stopCluster(cl)
    
}
 
```


- C. 
```{r}



f.cont <- range01(f.cont)


colors
g1 <- ggplot(site_date_asu$SEL107U_20200308_, aes(y=time_of_day, x=freq)) +
  geom_tile(aes(fill = f.cont)) +
  scale_fill_gradientn(colours = brewer.pal(9,"Reds"))+
    theme_bw()



g2 <- ggplot(plot_dat, aes(y=freq, fill= f.cont, x=time_of_day)) + 
  geom_density(alpha = 0.5) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
  theme_minimal_hgrid(12)


plot(x = freq, y = f.cont, type = "l", xlab = "Frequency(kHz)", 
            ylab = "Amplitude")




```


we will first get values for the mean frequency spectrum and calculate frequency peaks
```{r}
# Calculate mean frequency spectrum
# This function returns the mean frequency spectrum (i.e. the mean relative amplitude of the frequency distribution) of a time wave. Results can be expressed either in absolute or dB data.
mf <- meanspec(a,f=48000,wl=256,norm=F)

# This graphical function returns a frequency spectrum as a bar plot.
f_bands <- fbands(mf)

# Calculate frequency peaks
# This function searches for peaks of a frequency spectrum.
# Setting a threshold of 172, as specified in previous papers
f_peak <- fpeaks(mf, threshold = 0.003, freq = 172)
```






Campos-Cerqueira et al., 2019 inputs:
For meanspec: f=44,100, wl = 256, wn = ‘hanning’, norm = FALSE
Audio waveforms scaled between -1 and 1
Spectral peaks limited to max. amplitude of 1
Amplitude threshold = 0.003
Counted number of recordings with a peak in each of the 128 frequency bins (given amplitude threshold)