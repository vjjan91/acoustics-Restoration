---
editor_options: 
  chunk_output_type: console
---

# Non-metric multidimensional scaling of acoustic space use data

Here, we will use ordinations as a method of analyzing how acoustic space use (defined in terms of frequency and time, across 24 hours in a day) to test if space use follows a similar pattern of direction of change that was observed for species richness with the direction of change observed as moving from naturally regenerating sites to actively restored to benchmark sites. 

Load necessary libraries for analysis
```{r}
library(tidyverse)
library(dplyr)
library(stringr)
library(vegan)
library(ggplot2)
library(scico)
library(psych)
library(ecodist)
library(RColorBrewer)
library(ggforce)
library(ggalt)
library(indicspecies)

# Source any custom/other internal functions necessary for analysis
source("code/01_internal-functions.R")
```

Load the necessary data for nmds calculations
```{r}
# load the space use data
siteWiseAsu <- read.csv("data/site-wise-asu.csv")

# load list of sites
sites <- read.csv("data/list-of-sites.csv") %>%
  select("Site.code","Restoration.type")

# Add restoration type column to the space use data
siteWiseAsu <- left_join(siteWiseAsu,sites, by=c("Site"="Site.code"))

# Separate analysis: space use during certain times of day alone
# let's look only at dawn chorus to explore what the data looks like
dawn <- c("05:00-06:00","06:00-07:00","07:00-08:00","08:00-09:00",
          "09:00-10:00")
dawnChorusAsu <- siteWiseAsu %>%
  filter(time_of_day %in% dawn)

# Separate analysis: space use during certain times of day alone
# let's look only at dusk chorus to explore what the data looks like
dusk <- c("16:00-17:00","17:00-18:00","18:00-19:00","19:00-20:00")
duskChorusAsu <- siteWiseAsu %>%
  filter(time_of_day %in% dusk)
```

Preparing a dataframe of space use to run ordinations
```{r}

# Please note that while creating this dataframe for ordinations, the overall acoustic space use (sum of f.cont.sum column) was calculated by frequency bin, irrespective of the time of day for a given site. In other words, for 24 hours of data, a single value of space use was obtained for a given frequency bin. The frequency bin was pivoted from long to wide and each column essentially corresponded to a frequency bin. Within that frequency bin, grouped for each site, an overall value of space use was computed. 

nmdsDat <- siteWiseAsu %>% # replace with dawnChorusAsu/duskChorusAsu 
  dplyr::select(Site, freq, f.cont.sum, Restoration.type) %>%
  group_by(Site, Restoration.type, freq) %>%
  summarise(totSpaceuse = sum(f.cont.sum)) %>%
  arrange(Restoration.type) %>%
  pivot_wider (names_from = freq, values_from = totSpaceuse, values_fill = list(totSpaceuse=0))

# Convert to matrix form
nmdsDatMatrix <- as.matrix(nmdsDat[, 3:ncol(nmdsDat)])
```


Currently using a euclidean measure of estimating dissimilarity prior to running ordinations
```{r}
# Run a euclidean dissimilarity distance and use metaMDS function from vegan to run ordinations

disEuclidean <- vegdist(nmdsDatMatrix, method = "euclidean")

nmdsEuclidean <- vegdist (nmdsDatMatrix, method = "euclidean") %>% 
  metaMDS (nmdsEuclidean, k=6)

# extract nmds scores
nmdsScores <- as_tibble(scores(nmdsEuclidean))

# Write the scores to a separate .csv
write.csv(nmdsScores, "data/nmds-acousticSpaceUse.csv", row.names = F)

# With the above analysis, we note the stress is 0.009349337. However, if stress is high, we should reposition the points in 2 dimensions in the direction of decreasing stress, and repeat until stress is below some threshold.**A good rule of thumb: stress < 0.05 provides an excellent representation in reduced dimensions, < 0.1 is great, < 0.2 is good/ok, and stress < 0.3 provides a poor representation.** To reiterate: high stress is bad, low stress is good!
```


Plotting the NMDS scores using ggplot2
```{r}
# First let's add the treatment type back to the nmds scores
nmdsScores$Restoration.type <- nmdsDat$Restoration.type

# Add a custom set of colors
mycolors <- c(brewer.pal(name="Dark2", n = 3), brewer.pal(name="Paired", n = 3))

fig_nmds <- ggplot(data=nmdsScores) + 
  stat_ellipse(aes(x=NMDS1,y=NMDS2,colour=Restoration.type),level = 0.50) +
  geom_point(aes(x=NMDS1,y=NMDS2,shape=Restoration.type,colour=Restoration.type),size=4) + 
  theme_bw() +
  scale_x_continuous(name="NMDS 1") + 
  scale_y_continuous(name="NMDS 2") +
  scale_shape_manual(values= 1:length(unique(nmdsScores$Restoration.type)))+
  scale_color_manual(values=mycolors)+ theme(legend.key = element_blank(), legend.text = element_text(face = "italic"))

ggsave(fig_nmds, filename = "figs/fig_nmds_spaceUse.png", width=12, height=7,device = png(), units="in", dpi = 300); dev.off()

knitr::include_graphics("figs/fig_nmds.png")
```

Testing multivariate homogeneity of group dispersions

One measure of multivariate dispersion (variance) for a group of samples is to calculate the average distance of group members to the group centroid or spatial median (both referred to as 'centroid' from now on unless stated otherwise) in multivariate space. To test if the dispersions (variances) of one or more groups are different, the distances of group members to the group centroid are subject to ANOVA.

Betadisper tests whether two or more groups (for example, restored and unrestored sites) are homogeneously dispersed in relation to their species in studied samples. This test can be done to see if one group has more compositional variance than another. Moreover, homogeneity of dispersion among groups is very advisable to have if you want to test if two or more groups have different compositions, which is tested by adonis. 
```{r}
nmdsVariance <- betadisper(disEuclidean, group = nmdsDat$Restoration.type)
nmdsVariance

anova(nmdsVariance)
permutest(nmdsVariance, pairwise = TRUE, permutations = 999)
TukeyHSD(nmdsVariance)

# These results suggest that there is a significant difference in within group variance between one group and another (For Benchmark-Active sites and Passive-Benchmark sites)
```


Visualizing the multivariate homogeneity of group dispersions

The below lines of code have been adapted from: https://chrischizinski.github.io/rstats/adonis/
```{r}
# extract the centroids and the site points in multivariate space.  
centroids <-data.frame(grps=rownames(nmdsVariance$centroids),
                       data.frame(nmdsVariance$centroids))
vectors <- data.frame(group=nmdsVariance$group,
                      data.frame(nmdsVariance$vectors))

# to create the lines from the centroids to each point we will put it in a format that ggplot can handle
seg.data<-cbind(vectors[,1:3],centroids[rep(1:nrow(centroids),as.data.frame(table(vectors$group))$Freq),2:3])
names(seg.data)<-c("group","v.PCoA1","v.PCoA2","PCoA1","PCoA2")

# create the convex hulls of the outermost points
grp1.hull <- seg.data[seg.data$group=="Active",1:3][chull(seg.data[seg.data$group=="Active",2:3]),]
grp2.hull <- seg.data[seg.data$group=="Benchmark",1:3][chull(seg.data[seg.data$group=="Benchmark",2:3]),]
grp3.hull <- seg.data[seg.data$group=="Passive",1:3][chull(seg.data[seg.data$group=="Passive",2:3]),]
all.hull <- rbind(grp1.hull,grp2.hull,grp3.hull)

# plot the panel and convex hulls
fig_hull <- ggplot() + 
  geom_polygon(data= all.hull,aes(x=v.PCoA1,y=v.PCoA2),colour="black",alpha=0,linetype="dashed") +
  geom_segment(data=seg.data,aes(x=v.PCoA1,xend=PCoA1,y=v.PCoA2,yend=PCoA2),alpha=0.30) + 
  geom_point(data=centroids[,1:3], aes(x=PCoA1,y=PCoA2,shape=grps),size=4,colour="red") + 
  geom_point(data=seg.data, aes(x=v.PCoA1,y=v.PCoA2,shape=group),size=2) +
  labs(title="All",x="",y="") +
  #coord_cartesian(xlim = c(-0.2,0.2), ylim = c(-0.25,0.2)) +
  theme_bw() + 
  theme(legend.position="none")
```

Testing compositional dissimilarity between groups

We will do this by using the vegan::adonis() function which allows you to do permutational multivariate analysis of variance using distance matrices. In the above figure, the NMDS confidence ellipses suggest that there is a significant difference between benchmark and passive-active sites, but no difference between active and passive sites. Adonis works by first finding the centroids for each group and then calculates the squared deviations of each of site to that centroid. Then significance tests are performed using F-tests based on sequential sums of squares from permutations of the raw data. Please note that adonis analyzes and partitions sums of squares using distance matrices. It can be seen as an ANOVA using distance matrices (analogous to MANOVA - multivariate analysis of variance). Therefore, it is used to test if two or more groups have similar compositions.

```{r}
# We will use the NMDS scores for axis 1 and axis 2 to test for compositional dissimilarity
groups <- nmdsScores$Restoration.type

adonisNMDS <- adonis(nmdsDatMatrix ~ groups, method="bray",perm=999)
adonisNMDS

# The results suggest that there are significant compositional differences between groups.
```


